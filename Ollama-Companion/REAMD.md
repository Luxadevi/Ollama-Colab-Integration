# Ollama and quanting implement with streamlit


## How to run

Run Git clone this repo and start the install.sh or .ps1 file and it will install all dependencies.


Afterwards use streamlit run main.py to run the webinterface.

## Ollama companion and Quantizizer


To run the app with a cloudflare public url use the command python3 run_app.py


If you use this locally or dont want to share your ollama run streamlit run main.py

Use the Model Manager to show the models you have loaded up on your endpoint 
Fetch the models and use the dropdown to use them 
You can here show the modelinformation with the designated button or delete this model.


Use this tool to manage your Ollama,
Installs ollama locally or connects with already excisting ollama instance.


To install Git clone Luxapledevi/Ollama-Companion and use 
Sudo chmod +x install.sh to make the install script executable
Afterwards run ./install.sh you may get prompted for your password dont run this script with the sudo command.
